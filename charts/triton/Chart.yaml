apiVersion: v2
name: triton
description: NVIDIA Triton Inference Server with TensorRT-LLM support for optimized LLM inference
type: application
version: 0.1.0
appVersion: "25.08"
keywords:
  - triton
  - nvidia
  - inference
  - llm
  - tensorrt
  - ai-inference
maintainers:
  - name: metadist
    email: info@metadist.de
    url: https://github.com/metadist
sources:
  - https://github.com/metadist/synaplan-charts
  - https://github.com/triton-inference-server/server
